# 5. 가상메모리



### 1. 가상메모리

* 보조기억장치 이용하여, 프로그램 전체가 메모리에 올라오지 않아도 실행 가능하게 한 기법

  * 프로그램 크기 > 물리메모리의 가용 공간보다 커도 괜찮습니다.

* 배경

  * 다중 프로그래밍에선 여러 프로그램들이 동시에 메모리에 올라옴
  * 이때, 자주 사용되지 않는 코드도 올라옴 => 공간 낭비 발생
  * 그래서, 필요한 부분만 올리자는 가상 메모리 기법 등장
  
* 장점

  * 물리 메모리 크기에 제약 받지 않음 => 더 많은 프로그램 동시 실행 가능 => CPU 처리율 상승

  * 스와핑도 줄어서, 문맥교환도 감소하고, 프로그램을 빠르게 실행 가능

  * 공유 메모리 사용하게 함

    * 다른 프로세스의 페이지들이 같은 프레임을 가리키게 함 => 해당 프레임을 공유

      →   ex. 라이브러리를 여러 프로세스가 공유하는 것

      →   라이브러리가 올라간 물리 메모리 프레임을 모든 프로세스가 공유

* 가상 주소 공간 필요

  * 가상 주소 
    * CPU가 만드는 주소로, 가상메모리 주소이며, 프로그래밍할 때 쓰임
  * 당장은 필요하지 않은 프로그램의 메모리 공간을 올림
  * ex. 한 프로그램 실행 시, 논리 메모리 100KB 요구됨
    * 실행까지 필요한 유저 메모리 공간(Code, Data, Stack, Heap)의 합 40KB면, 이 부분을 물리 메모리에
    * 나머지 60KB는 가상메모리에 있다가 필요시 물리 메모리로
    * 즉, 유저 영역은 물리에, 나머지는 가상에



### 2. 요구 페이징(Demand Paging)

* 가상 메모리 관리 방식
* 프로그램 실행할 때, 프로그램 전체가 아니라 초기에 필요한 **페이지**만 물리 메모리에 적재
* 페이저 (Pager)를 통해

  * 개별 페이지 관리하고, 필요한 페이지만 메모리로 읽어 옴
* 페이지 부재

  * CPU에서 요청한 페이지가 메인 메모리에 없어 디스크에서 읽어오는 경우
  * 메모리 관리 장치(MMU)가 페이지 부재 트랩(인터럽트) 발생시킴
* 스와핑은 오버헤드가 큼 => 페이지 부재가 많이 발생하면 성능 저하됨
* 페이지 부재 시, 메인 메모리 자리 없다면, 기존 페이지와 교체됨

  1. 디스크에서 필요한 페이지 찾음

  2. 빈 페이지 프레임을 찾음

     * **페이지 교체 알고리즘**으로 희생될 페이지 고름

  3. 희생될 페이지를 디스크에 기록 & 관련 페이지 테이블 수정
      * 페이지 테이블 : 가상 주소와 물리 주소 매핑 기록
  4. 비워진 프레임에 새 페이지 읽어옴 & 페이지 테이블 수정

  5. 프로세스 재시작



### 3. 페이지 교체 알고리즘

* FIFO

  * 먼저 물리 메모리에 들어온 페이지가, 먼저 교체되어 나감

  * 장점

    * 프로그래밍이 쉬움

  * 단점

    * 초기 변수 등 필요한 정보를 가지는 등 많이 사용되는 오래된 페이지가 교체됨

      →   페이지 부재율 높임

    * Belady의 모순

      →   페이지 프레임 수를 늘렸는데, 페이지 부재가 더 많이 발생하는 현상

* 최적 페이지 교체 (Optimal Page Replacement; OPT)

  * Belady 모순을 계기로 탐구 진행됨
  * 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체
  * 장점
    * 알고리즘 중 가장 낮은 페이지 부재율
  * 단점
    * 모든 프로세스의 메모리 참조 계획을 미리 파악 불가능 => 실현 어려움

* LRU (Least Recently Used)

  * 가장 오랫동안 사용되지 않은 페이지 교체
  * OPT 근사
    * 실제로 가장 많이 쓰임

* LFU(Least Frequently Used)

  * 참조횟수 가장 적은 페이지 교체

  * 단점

    * 한 기능에서만 집중적으로 사용되던 페이지가, 다른 기능 사용시에도 불필요하게 메모리에 남음

      →   가장 많이 사용되는 페이지가 앞으로도 많이 사용될 거라는 가정에 어긋남

    * OPT에 근사하지 못함 →  잘 안 쓰임




### 4. 메모리 관리 장치 (Memory Management Unit; MMU)

* 가상주소(CPU가 만든 주소)를 물리주소로 변환하여, CPU가 가상 메모리를 통해, 물리메모리에 접근하게 하는 장치
  <img src="https://user-images.githubusercontent.com/70613905/178127477-0181a8ba-869c-4f53-8ae4-fe61c9c0cb81.JPG" alt="캡처" style="zoom:80%;" />

  * MMU 없으면 CPU가 직접 물리메모리에 접근해야해서, 가상 메모리만으로 물리메모리를 신경쓰지 않고 해결하게 하는 것이 MMU

  1. MMU는 CPU가 요구하는 가상/논리 주소를 물리 주소로 변환하여 물리메모리 접근
  2. 데이터 읽고, 그걸 다시 CPU에 전달

* 페이지 부재 시 트랩 발생시킴

* 메모리 보호도 가능

  * 프로세스는 독립적인 메모리 공간 가지며, 다른 프로세스 공간 접근 불가
  * 다른 프로세스의 메모리(물리) 공간으로 접근이 오면 trap 발생

  

### 5. 캐시 지역성

> 캐시 메모리
>
> * 속도 빠른 장치(CPU)와 느린 장치(메모리) 간 속도 차로 인해 발생하는 병목현상 줄이기 위한 메모리
> * CPU에게 필요한 예측해야 성능 좋아짐
> * 이를 위해 캐시 지역성이라는 개념을 이용합니다.

* 데이터 접근이 이전 데이터로부터 시간적, 공간적으로 가까운 곳에서 일어난다는 것
* 전제 조건
  * 프로그램은 모든 데이터에 균등하게 접근하지 않고, 특정 부분을 집중적으로 참조
* 종류
  * 시간 지역성(Temparal Locality)
    * 최근 참조된 데이터가 다시 참조될 가능성 큼
  * 공간 지역성(Spatial Locality)
    * 집중적으로 참조된 주소 근처의 데이터가 다시 참조될 가능성 큼
* 캐싱 라인
  * 캐시 메모리에서 데이터 읽어오는 단위
  * 캐시 데이터 메모리 주소를 기록한 태그들의 묶음
  * 필요성
    * 참조하려는 데이터에 바로 접근하기 위해