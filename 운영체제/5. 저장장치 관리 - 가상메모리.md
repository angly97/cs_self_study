# 5. 가상메모리



### 1. 가상메모리

* 보조기억장치 이용하여, 프로그램 전체가 메모리에 올라오지 않아도 실행 가능하게 한 기법

  * 프로그램 크기 > 물리메모리 내 가용 공간 이어도 OK

* 배경

  * 다중 프로그래밍에선 많은 프로그램들이 동시에 메모리에 올라옴
  * 프로그램 전체가 올라오기에 가끔 사용되는 코드도 메모리 차지
  * 남은 메모리보다 큰 프로그램일 경우 실행 불가

* 장점

  * 물리 메모리 크기 제약 받지 않게됨

  * 더 많은 프로그램 동시 실행 가능

    * CPU 이용률, 처리율 상승

  * swap이 줄어 프로그램 빠른 실행 가능

    * 문맥교환 감소

  * 공유 메모리 사용하게 함

    * 다른 프로세스의 각 페이지들이 같은 프레임을 가리키게 함 => 해당 프레임을 공유

      ​	→   ex. 라이브러리가 여러 프로세스에서 공유되게 함

      ​	→   라이브러리가 올라간 물리 메모리 페이지를 모든 프로세스가 공유

      ​	→   fork()로 프로세스 생성 시, 페이지 공유를 가능하게 함

* 가상 주소 공간

  * 가상 주소 
    * CPU가 만드는 주소로, 프로그래밍 시 쓰는 주소
  * 한 프로세스가 메모리에 저장되는 모습을 가상 메모리에 구현한 공간
  * 현재 직접적으로 필요하지 않은 프로그램 메모리 공간을 올림
  * ex. 한 프로그램 실행 시, 논리 메모리 100KB 요구됨
    * 실행까지 필요한 메모리 공간(Heap, Stack, Code, Data)의 합 40KB면, 이 부분문 물리 메모리에
    * 나머지 60KB는 가상메모리에 있다가 필요시 물리 메모리로



### 2. 요구 페이징(Demand Paging)

* 가상 메모리 관리 방식

* 프로그램 실행 시작 시, 프로그램 전체가 아니라 초기에 필요한 **페이지**만 디스크에서 물리 메모리로 적재

* 페이저(Pager)

  * 프로세스 내 개별 페이지 관리
  * 필요한 페이지들만 메모리로 읽어 옴
  * 한 번도 접근되지 않은 페이지는 적재 X

* 페이지 부재

  * CPU에서 요청한 페이지가 메인 메모리에 없어 디스크에서 읽어오는 경우 MMU가 페이지 부재 트랩 발생시킴(인터럽트)

  * swap은 오버헤드가 큼

    * 요구 페이징 기법은 페이지 부재 발생률이 성능에 큰 영향 미침

  * 페이지 부재 시, 메인 메모리 자리 없다면, 기존 페이지와 교체되야 함

    1. 디스크에서 필요한 페이지 위치 찾음

    2. 빈 페이지 프레임을 찾음

       * **페이지 교체 알고리즘**으로 희생될 페이지 고름

       * 희생될 페이지를 디스크에 기록 & 관련 페이지 테이블 수정

         →   페이지 테이블 : 가상 주소와 물리 주소 매핑 기록

    3. 새로 비워진 페이지 테이블 내 프레임에 새 페이지 읽어옴 & 프레임 테이블 수정

    4. 프로세스 재시작



### 3. 페이지 교체 알고리즘

* FIFO

  * 먼저 물리 메모리에 들어온 페이지가 먼저 교체되어 나감

  * 장점

    * 프로그래밍이 쉬움

  * 단점

    * 초기 변수 등 필요한 정보를 가진 & 활발하게 사용되는 오래된 페이지가 교체됨

      →   페이지 부재율 높임

    * Belady의 모순

      →   페이지 프레임 수를 늘려도 페이지 부재 더 많이 발생하는 모순

* 최적 페이지 교체(Optimal Page Replacement; OPT)

  * Belady 모순을 계기로 탐구 진행됨
  * 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체
  * 장점
    * 알고리즘 중 가장 낮은 페이지 부재율
  * 단점
    * 모든 프로세스의 메모리 참조 계획을 미리 파악 불가능 => 실현 어려움

* LRU (Least Recently Used)

  * 가장 오랫동안 사용되지 않은 페이지 교체
  * OPT 근사
    * 실제로 가장 많이 쓰임

* LFU(Least Frequently Used)

  * 참조횟수 가장 적은 페이지 교체

  * 단점

    * 한 기능 사용 시에 집중적으로 참조되던 페이지가, 다른 기능 사용시에도 불필요하게 메모리에 남음

      →   가장 활발히 사용되는 페이지가 참조횟수 많아질거라는 가정에 어긋남

    * OPT에 근사하지 못함

      →   잘 안 쓰임



### 4. MMU(Memory Management Unit)

* CPU가 가상 메모리만으로 물리메모리도 관리하게 하는 하드웨어 장치

  1. CPU가 필요한 데이터가 메모리에 없어서 가상 메모리 접근 필요
  2.  MMU가 논리 주소를 물리 주소로 변환하여 물리메모리 접근 & 데이터 읽음 
  3. 그 데이터를 다시 CPU에 전달 

* 메모리 보호도 가능

  * 프로세스는 독립적인 메모리 공간 가져야하고, 다른 프로세스 공간 접근 불가

  * 한 프로세스에게 주소 영역 설정하고, 잘못된 접근이 오면 trap 발생

    * 잘못된 접근 

      →   base <= x < base + limit  범위 벗어나는 접근

      >base : 물리 메모리 상 프로세스 시작 주소 
      >
      >limit : 프로세스 사이즈



### 4. 캐시 지역성

* 캐시 메모리
  * 속도 빠른 장치(CPU)와 느린 장치(메모리) 간 속도 차로 인한 병목현상 줄이기 위한 메모리
  * CPU가 어떤 데이터를 원할 지 예측해야 성능 좋아짐
  * 이를 위해 지역성의 원리 사용
* 전제 조건
  * 프로그램은 모든 데이터에 균등하게 접근하지 않고, 특정 부분을 집중적으로 참조
* 종류
  * 시간 지역성(Temparal Locality)
    * 최근 참조된 데이터가 다시 참조될 가능성 큼
  * 공간 지역성(Spatial Locality)
    * 집중적으로 참조된 데이터 근처의 주소가 참조될 가능성 큼
* 캐싱 라인
  * 캐시 메모리 내 참조 시, 데이터 읽어오는 단위
  * 캐시 데이터 메모리 주소를 기록한 태그들의 묶음
  * 필요성
    * 참조하려는 데이터에 바로 접근하기 위해